\chapter{Off-line computation of audio features} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 5. \emph{Off-line computation of audio features}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title
In order to achieve good performance, two very computationally intensive tasks of the system are performed off-line, and their output is then going to be used by the real-time application. These tasks consist of the computation of the audio content descriptors and of the building of a \textit{fast-map}, a high dimensionality space in which each point correspond to an audio musical excerpt. This space is built in a fashion that guarantees that nearby points of this space correspond to very similar excerpts.


\section{Audio content features extraction}
Solving this problem has involved two very important choices: what audio content descriptors to use and what library or tool to use for computing them. Many factors have been taken into account for solving both of these problems.\\ 
\begin{itemize}
\item Among the features of the tools, flexibility has constituted the strictest requirement: an easy way to compute descriptors for each excerpt of every track is required, while many tools provide only ways of computing descriptors for the entire file. In this latter case, the file should manually split into \textit{subfiles} (one for each segment), therefore implying a huge waste of memory. This has soon lead to the exclusion of \textit{jMir}, for it doesn't fulfill this requirement.
\item The tool should easily be callable by source code or bash scripts, and results of the analysis must be stored in output files.
\item The computation of descriptors should be as fast as possible, given that the excerpts to be analyzed are in the order of tens of thousands.
\item Last but not least, the tool must provide descriptors whose usefulness for this specific case study has been empirically verified during the development of the system.
\end{itemize}

All of these requirements lead to the choice of performing the audio analysis with Essentia and Echo Nest: the first for its speed, flexibility and reliability. Echo Nest has been used for some of its descriptors are not present or not as accurate in Essentia, and have shown a great usefulness during the development or granted by existing previous research. \\ Furthermore, both of the two libraries are offered in Python, allowing the entire analysis task to be written in a single programming language, therefore improving the code consistency and readability. \\
The schema for the extraction of the audio features is illustrated in figure \ref{fig:extraction}. \\ 
\begin{figure}[h]\hskip -1cm
\begin{tikzpicture}[auto, thick, node distance=2cm, >=triangle 45]
	\draw
	% Drawing the blocks
	node at (0.5,-0.8) [block] (track) {Track}
	node at (4.8,-0.8)[align=center] [block] (enanalysis) {Echo Nest\\Analysis}
	node at (10.7,-0.8)[align=center][block] (bar) {Bar Analysis\\(Essentia)}
	node at (15.2, -1.2) [draw, cylinder, shape border rotate=90, aspect=0.35, %
      minimum height=40, minimum width=60] (output) {Output File};
	;
    % Joining blocks. 
	\draw[->](track) -- node[align=center]{$get$ $E.N.$\\$analysis$}(enanalysis);
 	\draw[->](enanalysis) -- node[align=center] {$for$ $each$ $bar$\\$found$ $by$ $E.N.$} (bar);
 	\draw[->](bar.east) -- node[align=center] {$store$\\$analysis$} (output.west|-bar.east);

	% Boxing and labelling
	\draw [color=gray,thick](-0.5,-3) rectangle (16.5,1);
	\node at (-0.5,1) [above=5mm, right=0mm] {\textsc{Analysis of one track}};
\end{tikzpicture}
\caption{Schema for the extraction of audio features.}
\label{fig:extraction}
\end{figure}
At first, the user is required to give the path of the folder in which the audio files are stored. The collection is entirely stored as .mp3 files with a sample rate of 44100Hz and a bitrate of 192kbps. The application then collects the path to all the .mp3 files in this folder, and mark them as to be analyzed if no previous analysis has be performed. An analysis of these files with Echo Nest (through Pyechonest) is performed, and we specifically use the following fields of the output of this analysis: \textit{bars}, \textit{BPM}, \textit{loudness}, \textit{HPCP} and \textit{acousticness}. \textit{Bars} give the starting and ending point of each bar detected and, although not particularly meaningful for the arrhythmic
 Phonos catalogue of music, have shown to perform well on the additional and more generic personal catalogue used during first stages of development; therefore, it was decided to use them in order to improve the flexibility of the system. \\ Segmentation of songs into excerpts is then performed, based on starting and ending point of each bar. Then, we compute more specific descriptors with Essentia for these excerpts, with the following strategy:
\begin{itemize}
\item each excerpt is divided into frames, with a size of 2048 samples and a hop of 1024 samples. For each of these frames:
\begin{itemize}
\item we apply an Hann windowing function
\item we apply the FFT algorithm provided by Essentia in order to get a spectral representation of the signal
\item we look for peaks in the spectrum, collecting their frequencies and magnitudes, and then we use them to compute the dissonance in the frame, with Essentia's algorithm \texttt{Dissonance}
\item an HFC onset function is computed on the spectrum, that will be used afterwards to compute the onset times
\item the MFCC bands and coefficients are computed with Essentia's algorithm \texttt{Mfcc}\footnote{Essentia uses the MFCC-FB40 implementation, which decomposes the signal into 40 bands from 0 to 11000Hz, takes the log value of the spectrum energy in each mel band and finally applies a Discrete Cosine Trasform of the 40 bands down to 13 mel coefficients.} 
\item the energy in 27 Bark bands of the spectrum is computed 
\begin{figure}[h]\hskip -1cm
\begin{tikzpicture}[auto, thick, node distance=2cm, >=triangle 45]
	\draw
	% Drawing the blocks
	node at (0.5,-0.5) [block] (excerpt) {Excerpt}
	node at (4.3,-0.5)[align=center] [block] (frame) {Frame}
	node at (8.4,-0.5)[align=center][block] (spectrum) {Spectral Analysis}
	node at (14.2,-0.5)[align=center][block] (peaks) {Dissonance}
	node at (14.2,-3.4)[align=center][block] (onset) {Onsets}
	node at (8,-3.8)[align=center][block] (mfcc) {MFCC}
	node at (4.8,-3.8)[align=center][block] (barks) {Energy in \\ Bark bands}
	;
    % Joining blocks. 
	\draw[->](excerpt) -- node[align=center]{$frame$\\$generation$}(frame);
 	\draw[->](frame) -- node[align=center] {$FFT$} (spectrum);
 	\draw[->](spectrum.east) -- node[align=center] {$peaks$\\$analysis$} (peaks.west);
 	\draw[->](spectrum) -- node[align=center] {$HFC$ $onset$\\$detector$} (onset.west);
 	\draw[->](spectrum) -- node[align=center, right] {$MFCC$\\$computation$} (mfcc.north);
 	\draw[->](spectrum) -- node[align=center, left] {$analysis$ $of$\\$Bark bands$} (barks.north);

	% Boxing and labelling
	\draw [color=gray,thick](-0.5,-5) rectangle (16.5,1);
	\node at (-0.5,1) [above=5mm, right=0mm] {\textsc{Low level features extraction}};
\end{tikzpicture}
\caption[Schema for the extraction of low level features from excerpts]{Schema for the extraction of low level audio features from excerpts.}
\label{fig:extraction}
\end{figure}
\end{itemize}
\item onset times in the excerpt are calculated, according to the onset function computed in each frame, and then onset rate is calculated with the formula:
\begin{equation}
OR_{excerpt} = \frac{Onsets_{excerpt}}{Length_{excerpt}}
\end{equation}
\item dissonance in the excerpt is computed as a mean of the dissonance in each of its frames
\item a single Gaussian model for the collected MFCC values is computed. Specifically, we collect its mean, covariance and inverse covariance. Mean is a $13$ size vector, while covariance and inverse covariance are $13$x$13$ matrices. The inverse covariance is stored in order to prevent having to compute it in the real-time application or during the fast map computation, therefore increasing the performance of both these stages. If a problem of ill-conditioned covariance matrices is encountered (i.e., a not positive semi-definite covariance matrix has been computed), only values of the diagonal of these problematic covariance matrices are used. This has allowed to avoid the presence of outliers when computing similarity, while still taking into account excerpts for which a covariance matrix of the MFCC values could not be correctly computed. 
\item based on the HPCP values computed by Echo Nest, we use Essentia's \texttt{Key Detector} to associate a key to each first and fourth beat of the bar. The reason why we keep values for these two particular beats is that this allows us to perform a more precise tonal comparison when trying to merge two excerpts in the real-time application: if the key of the first beat of the inspected excerpt is very different from the key of the fourth beat of the excerpt for which we're looking for similar pieces, the candidate is discarded.
\end{itemize} 
This procedure is repeated for each excerpt, in order to get a deep description for all of them and perform more precise similarity computation in the real-time application. In addition, we store some additional level-song descriptors, specifically artist, title and year of release, and acousticness (computed with Echo Nest). Finally, for each song we create a corresponding JSON file in which we store all the descriptors computed. \\
The list of descriptors computed during this task is summarized in table~\ref{table:offlinedescriptors}.

\begin{center} 
\begin{longtable}{ p{.15\textwidth}  p{.13\textwidth}  p{.15\textwidth}  p{.55\textwidth} } 
\textbf{Features} & \textbf{Source} & \textbf{Level} & \textbf{Motivation} \\ \toprule
Title, Artist, Year & Provided & Song-Level & Display more information about the current playing track in the GUI \\ \midrule
Acousticness & Echo Nest & Song-Level & Give the user the chance to filter music in regards to its nature (acoustic or electronic music) \\ \midrule
MFCC & Essentia & Bar-Level & Timbre similarity computation \\ \midrule
BPM & Echo Nest & Bar-Level & Avoid consecutive excerpts with very different BPM \\ \midrule
Onset Rate & Essentia & Bar-Level & Give the user the chance to filter music in regards to the presence of percussive elements \\ \midrule
Dissonance & Essentia & Bar-Level & Give the user the chance to filter music in regards to the dissonance\footnote{During development, it has been empirically noticed that dissonance has a significant correlation to the perception of noise: the more an excerpt is perceived as noisy, the more it is dissonant.} of excerpts \\ \midrule
Loudness & Echo Nest & Bar-Level & Give the user the chance to filter music in regards to its loudness \\ \midrule
Bark Bands & Essentia & Bar-Level & Give the user the chance to filter music in regards to its ``sparseness'', i.e. the amount of mel bands with significant energy level \\ \midrule
HPCP & Echo Nest & Beat-Level & Use them to compute key \\ \midrule
Key & Essentia & Beat-Level & Use them to discard the possibility of having two consecutive dissonant excerpts in the playlist \\ \bottomrule
\caption[List of descriptors computed offline]{Descriptors computed by the offline application.}
\label{table:offlinedescriptors}
\end{longtable}
\end{center}


\section{FastMap computation}
\label{sec:fastmap}
The procedure just described for computing descriptors give us a 410 size vector for each excerpt, and a total number of 159239 excerpts.\\
In order to achieve good real-time performance when comparing these excerpts, a dimensionality reduction of these vectors is required. Furthermore, as seen in \ref{sec:audiocontentsimilarity}, the computation of Kullback-Leibler divergence, although showing very good results in capturing the timbre similarity, is a very intensive computational operation and therefore a simpler distance measure with comparable results is preferred. \\
These requirements were also faced by Schnitzer et al. in \cite{fastmap12}, who presented a filter-and-refine method to speed up nearest neighbor searches with the Kullback-Leibler divergence for multivariate Gaussians, yielding high recall values of 95-99\% compared to a standard linear search. The original FastMap was proposed in 1995 by Faloutsos and Lin \cite{falo95} for indexing and data-mining multimedia datasets. It was used for the first time for computationally heavy, non-metric measures and nearest neighbor retrieval in \cite{athi04}, for speeding up classification of handwritten digits. FastMap was used for the first time in MIR by Cano et al. in \cite{cano02} in the attempt of reducing high dimensional music timbre similarity space into a 2-dimensional space. This was done not for speeding up classification, but rather for visualization purposes. \\
The idea behind the use of a FastMap for classification or computing similarities is to compute with the original distance measure $D()$ (computationally intensive) just a subset of all the distances, specifically the distances between each point and a subset of $2k$ points (the \textit{``pivots''}); then, on the basis of these computed distances, each feature vector is mapped with a non-linear trasformation into a point of a $k$-dimension space, where a simpler distance measure can be applied, with a small decrement in accuracy.

For choosing the $2k$ pivot elements, the original FastMap \cite{falo95} follows this strategy:
\begin{itemize}
\item $k$ element $x_1^1, x_2^1, ..., x_k^1$ are randomly selected from the collection of feature vectors
\item for each $x_i^1$, its corresponding most distant object $x_i^2$ according the original distance measure $D()$ is picked
\end{itemize}

Each vector of features $x$ is then mapped into the point $(F_1(x), ..., F_k(x))$ of the new $k$-dimensional space, where $F_j(x)$ is computed with the formula:
\begin{equation}
\label{eq:fastmapeq}
F_j(x) = \frac{D(x, x_j^1)^2 + D(x_j^1, x_j^2)^2 - D(x, x_j^2)^2}{2D(x_j^1, x_j^2)}
\end{equation}
In other words, the coordinate in the $j-th$ dimension of each point is determined by the pair $(x_j^1, x_j^2)$, specifically by the original distance (computed with $D()$) of the point from both these pivots and the distance between the pivots themselves. \\
For our work, we have decided to use the Kullback-Leibler as the original distance function, computed for the multivariate normal distributions $x_1$ and $x_2$ with the Eq.~\ref{eq:kl_norm}, that for convenience we report again here:
\begin{equation}
KL(x_1, x_2) = \frac{1}{2}\left(tr(\Sigma_{x_2}^{-1}\Sigma_{x_1}) + (\mu_{x_2} - \mu_{x_1})^T \Sigma_{x_2}^{-1}(\mu_{x_2} - \mu_{x_1}) - k + ln\left(\frac{det\Sigma_{x_2}}{det\Sigma_{x_1}}\right)\right)
\end{equation}
As it has been widely used (achieving good results in \cite{mirage07}, \cite{perfe11}, and \cite{fastmap12}), we can be very confident on using it here too. Anyways, we must take into account several aspects. \\ 
As already seen in \ref{sec:audiocontentsimilarity}, the Kullback-Leibler cannot be intended as a pure distance measure, for it fails to be symmetric and to fulfill the triangle inequality. It can simply be made symmetric by considering the distance $SKL$ (symmetric Kullback-Leibler) defined as:
\begin{equation}
SKL(x_1, x_2) = \frac{1}{2}KL(x_1, x_2) + \frac{1}{2}KL(x_2, x_1)
\end{equation}
Regarding the triangle inequality, a proper solution is not that trivial. However, in \cite{fastmap12} Schnitzer et al. have shown that rescaling the symmetric Kullback-Leibler divergence with the square root leads the new distance function to fulfill the triangle inequality in more than 99\% of the cases. Therefore our original distance function $D()$ that we use in Eq.~\ref{eq:fastmapeq} is:
\begin{equation}
\label{eq:distance_func}
D(x_1, x_2) = \sqrt{SKL(x_1, x_2)} = \sqrt{\frac{1}{2}KL(x_1, x_2) + \frac{1}{2}KL(x_2, x_1)}
\end{equation}

This procedure can be further improved by a small modification in the strategy for choosing pivots: once the pivot $x_i^1$ is randomly picked, we choose to pick the object lying at the distance media as $x_i^2$, i.e. the object at the index j=$ \lfloor \frac{N}{2} \rfloor$ once all the distances from point $x_i^1$ are sorted. We have decided to use $k=20$ (therefore having 20 pairs of pivots and a final 20-dimensional space) as this has allowed us to find a good balance between computational times and quality of the output the similarity computation.\\
The accuracy and performance of this procedure are well-documented in \cite{fastmap12}. This technique constitutes the basis on which our system will perform the real-time similarity computation, with some additional tweak that will see in the Chapter~\ref{Chapter6}. \\
The computed data is stored on a JSON file: for each point (corresponding to an excerpt), we store its coordinates in the new 20-dimensional space plus some additional descriptors that allow us to do a faster filtering in the real-time application, as we won't need to lookup to the original JSON descriptor file for each song just for retrieving the values of these descriptors. The list of features stored in the map for each point is shown in table~\ref{table:fastmap}.\\During this stage, we additionaly save lists that associate each segment to the decade the song it has been extracted from has been produced. This will allow very fast filtering techniques on the real-time application when the user interacts with the sliders for selecting music according to the year of release. \\The computational times of this stage are shown in table~\ref{table:benchmarkoffline} and the configuration of the computer used in table~\ref{table:hardwareoffline}.


\begin{center}
\begin{longtable}{ p{.35\textwidth}  p{.65\textwidth} } 
\textbf{Features} &  \textbf{Motivation} \\ \toprule
Year, Artist, Title & Speed up access to information\\ \midrule
Starting and ending point inside the track & Allows fast extraction of the excerpt from the entire audio signal \\ \midrule
BPM, Key & Be faster when filtering out music with very different BPM or key\\ \midrule
Acousticness, Loudness, Dissonance, Bark Bands, Onset Rate & Perform a fast filtering of database of excerpt when the user interacts with the GUI for controlling the musical output\\ \bottomrule
\caption[Features stored in the map]{Features stored in the map for each point.}
\label{table:fastmap}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{ p{.25\textwidth}  p{.45\textwidth} } 
\toprule
\textbf{Laptop Model} & Packard Bell EasyNote TS-11HR \\ \midrule
\textbf{CPU}         & Intel\textregistered  Core\texttrademark i5-2410M @ 2.50GHz \\ \midrule
\textbf{RAM}        & 4GB DDR3 @ 1066MHz \\ \midrule
\textbf{Hard Disk Drive} & 5400rpm \\ \midrule
\textbf{OS}        & Linux Mint 17.1 ``Rebecca'' (64 bit) \\ \bottomrule
\caption[Hardware configuration of computer used during off-line descriptors computation]{Hardware configuration of computer used during off-line descriptors computation.}
\label{table:hardwareoffline}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{ p{.2\textwidth}  p{.25\textwidth}  p{.4\textwidth} } 
\textbf{Stage} & \textbf{Time required} & \textbf{Stats} \\\toprule
\multirow{2}{80pt}{\textbf{Descriptors computation}} & \multirow{0}{80pt}{04h 32m 25s} & Minimum time for track: 00m 15s  \\ \cmidrule(lr){3-3}
& & Maximum time for track: 00m 52s \\ \cmidrule(lr){3-3}
& & Average time for track: 00m 28s \\ \midrule
\multirow{2}{80pt}{\textbf{FastMap computation}} & 00h 47m 12s & Choosing pivots: 16m 43s \\ \cmidrule(lr){3-3}
& & Computing points coords: 30m 29s \\ \midrule
\textbf{Total} & 05h 19m 37s & \\ \bottomrule
\caption[Computational times for descriptors computation]{Computational times for descriptors computation of a collection of 584 tracks, with a total length of 91 hours, 43 minutes and 35 seconds (the time for uploading these tracks to Echo Nest is not considered in these results).}
\label{table:benchmarkoffline}
\end{longtable}
\end{center}


The features collected and the FastMap computed over this stage will constitute the basis on which the real time computation of music similarity will be performed; this particular core of the system will be shown and discussed in next section.